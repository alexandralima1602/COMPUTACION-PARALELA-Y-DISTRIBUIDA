{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fd13fa-b393-479b-9926-ed9b0a805e6f",
   "metadata": {},
   "source": [
    "### Paralelismo de datos\n",
    "\n",
    "El paralelismo de datos es una técnica de computación paralela donde se divide un conjunto de datos en partes más pequeñas que pueden ser procesadas simultáneamente por múltiples procesadores o núcleos de procesamiento. A diferencia del paralelismo de tareas, donde diferentes tareas o funciones son ejecutadas en paralelo, el paralelismo de datos se centra en aplicar la misma operación a diferentes fragmentos de datos de manera concurrente. Esta técnica es particularmente efectiva en aplicaciones que involucran grandes volúmenes de datos y operaciones repetitivas.\n",
    "\n",
    "**Conceptos fundamentales**:\n",
    "\n",
    "División de datos:\n",
    "\n",
    "- Segmentación: Los datos se segmentan en bloques que pueden ser procesados independientemente. Por ejemplo, en el procesamiento de imágenes, una imagen puede dividirse en múltiples segmentos, y cada segmento puede ser procesado por un núcleo diferente.\n",
    "- Distribución: Los datos segmentados se distribuyen entre los procesadores disponibles. Esta distribución debe ser balanceada para asegurar que cada procesador tenga una cantidad similar de trabajo, minimizando así el tiempo total de ejecución.\n",
    "\n",
    "Operaciones similares:\n",
    "\n",
    "- Aplicación de la misma operación: Cada procesador aplica la misma operación a su segmento de datos. Esto es eficiente en algoritmos como el procesamiento de matrices, transformadas de Fourier, y en la mayoría de las operaciones aritméticas en vectores.\n",
    "- Independencia de los datos: Las operaciones deben ser independientes entre sí para evitar conflictos y asegurar que no se necesiten sincronizaciones complejas.\n",
    " \n",
    "\n",
    "**Implementaciones y arquitecturas**\n",
    "\n",
    "Vectorización:\n",
    "\n",
    "- Procesadores SIMD (Single Instruction, Multiple Data): En estos procesadores, una sola instrucción es aplicada a múltiples datos simultáneamente. SIMD es común en unidades de procesamiento gráfico (GPU) y en algunas extensiones de conjuntos de instrucciones de CPU como SSE (Streaming SIMD Extensions) y AVX (Advanced Vector Extensions).\n",
    "- Ejemplos: Operaciones como la suma de vectores, multiplicación de matrices, y filtrado de imágenes se benefician enormemente de la vectorización.\n",
    "\n",
    "Arquitectura de memoria compartida:\n",
    "\n",
    "- Multiprocesadores de memoria compartida: En estas arquitecturas, múltiples procesadores comparten una única memoria principal. La sincronización y la coherencia de caché son críticas en estos sistemas para asegurar que todos los procesadores trabajen con datos consistentes.\n",
    "- OpenMP: Es una API para programación paralela en sistemas de memoria compartida. Permite a los programadores especificar de manera sencilla las partes del código que deben ser paralelizadas.\n",
    "\n",
    "Arquitectura de memoria distribuida:\n",
    "\n",
    "- Clusters y grids: En sistemas de memoria distribuida, cada procesador tiene su propia memoria local. Los datos deben ser explícitamente enviados entre procesadores, generalmente mediante un mecanismo de paso de mensajes.\n",
    "- MPI (Message Passing Interface): Es un estándar para la programación paralela en sistemas de memoria distribuida. Permite la comunicación eficiente entre procesos que se ejecutan en diferentes nodos de un cluster.\n",
    "\n",
    "**Aplicaciones y ejemplos**\n",
    "\n",
    "Procesamiento de imágenes:\n",
    "\n",
    "- Filtrado y Transformaciones: Operaciones como la convolución y las transformadas de Fourier en imágenes se pueden paralelizar dividiendo la imagen en bloques y aplicando la operación a cada bloque simultáneamente.\n",
    "- Ejemplo práctico: En el procesamiento de video, cada cuadro puede ser segmentado y procesado en paralelo para efectos como el suavizado, la detección de bordes, y la compresión.\n",
    "\n",
    "Computación científica:\n",
    "\n",
    "- Simulaciones: Simulaciones de sistemas físicos, como dinámica molecular o simulaciones de clima, pueden paralelizarse dividiendo el espacio físico en subregiones, cada una procesada en paralelo.\n",
    "- Ejemplo práctico: En una simulación de dinámica de fluidos, el dominio de simulación puede dividirse en celdas, y el cálculo del flujo en cada celda se realiza en paralelo.\n",
    "\n",
    "Big Data y análisis de datos:\n",
    "\n",
    "- MapReduce: Es un modelo de programación que permite el procesamiento de grandes conjuntos de datos en paralelo. Los datos se dividen en fragmentos y se procesan en paralelo mediante funciones de mapeo y reducción.\n",
    "- Ejemplo práctico: Procesos de ETL (Extract, Transform, Load) en bases de datos grandes se benefician del paralelismo de datos para extraer, transformar y cargar datos de manera eficiente.\n",
    "\n",
    "**Desafíos y consideraciones**\n",
    "\n",
    "Equilibrio de carga:\n",
    "\n",
    "- Desbalanceo de carga: Un desafío importante en el paralelismo de datos es asegurar que todos los procesadores tengan una cantidad equitativa de trabajo. Si algunos procesadores terminan antes que otros, los recursos no se utilizan de manera eficiente.\n",
    "- Técnicas de equilibrio: Estrategias como el balanceo dinámico de carga y la redistribución de datos en tiempo de ejecución pueden ayudar a mitigar este problema.\n",
    "\n",
    "Comunicación y sincronización:\n",
    "\n",
    "- Latencia y ancho de banda: En arquitecturas de memoria distribuida, la latencia de comunicación y el ancho de banda son factores críticos. Una comunicación excesiva puede reducir significativamente los beneficios del paralelismo.\n",
    "- Barreras y sincronización: La necesidad de sincronización entre procesadores puede introducir esperas y reducir la eficiencia. El diseño de algoritmos debe minimizar estas sincronizaciones.\n",
    "\n",
    "Coherencia de memoria:\n",
    "\n",
    "- Incoherencia de caché: En sistemas de memoria compartida, mantener la coherencia de caché es esencial para asegurar que todos los procesadores trabajen con datos actualizados.\n",
    "- Protocolos de coherencia: Protocolos como MESI (Modified, Exclusive, Shared, Invalid) y MOESI (Modified, Owner, Exclusive, Shared, Invalid) se utilizan para gestionar la coherencia de caché."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6a5aa-b0e8-4f5d-93bf-ae8712316e05",
   "metadata": {},
   "source": [
    "#### Ejercicios de paralelismo de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7cf13-0141-4bca-9453-df1405428db0",
   "metadata": {},
   "source": [
    "\n",
    "Ejercicio 1: Procesamiento paralelo de imágenes con OpenCV y Multiprocessing\n",
    "Descripción: Divide una imagen en varios segmentos y aplica un filtro (por ejemplo, filtro de desenfoque) a cada segmento en paralelo usando el módulo multiprocessing.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Cargar una imagen utilizando OpenCV.\n",
    "- Dividir la imagen en segmentos.\n",
    "- Aplicar un filtro de desenfoque a cada segmento en paralelo.\n",
    "- Unir los segmentos procesados y guardar la imagen resultante.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa cv2.imread para cargar la imagen.\n",
    "- Usa multiprocessing.Pool para el procesamiento paralelo.\n",
    "- Usa numpy.hstack o numpy.vstack para unir los segmentos procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c3d0c7-9f9e-4272-90e4-f4452382bb3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def apply_blur(segment):\n",
    "    return cv2.GaussianBlur(segment, (15, 15), 0)\n",
    "\n",
    "def parallel_image_processing(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    segments = np.array_split(image, 4, axis=1)\n",
    "\n",
    "    with Pool(processes=4) as pool:\n",
    "        blurred_segments = pool.map(apply_blur, segments)\n",
    "\n",
    "    blurred_image = np.hstack(blurred_segments)\n",
    "    cv2.imwrite('blurred_image.jpg', blurred_image)\n",
    "\n",
    "parallel_image_processing('input_image.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce06e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\alexandra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\alexandra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def5fc8c-6fbc-4df7-b011-549899abf39b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     blurred_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(blurred_segments)\n\u001b[0;32m     19\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mque-es-la-informatica-900x445.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, blurred_image)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mparallel_image_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_image.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m, in \u001b[0;36mparallel_image_processing\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_image_processing\u001b[39m(image_path):\n\u001b[0;32m     11\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m---> 12\u001b[0m     height, width, _ \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m     13\u001b[0m     segments \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(image, \u001b[38;5;241m4\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "## Tus respuestas\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def apply_blur(segment):\n",
    "    return cv2.GaussianBlur(segment, (15, 15), 0)\n",
    "\n",
    "def parallel_image_processing(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    segments = np.array_split(image, 4, axis=1)\n",
    "\n",
    "    with Pool(processes=4) as pool:\n",
    "        blurred_segments = pool.map(apply_blur, segments)\n",
    "\n",
    "    blurred_image = np.hstack(blurred_segments)\n",
    "    cv2.imwrite('que-es-la-informatica-900x445.jpg', blurred_image)\n",
    "\n",
    "parallel_image_processing('input_image.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6611c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def apply_blur(segment):\n",
    "    return cv2.GaussianBlur(segment, (15, 15), 0)\n",
    "\n",
    "def parallel_image_processing(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: No se pudo cargar la imagen '{image_path}'\")\n",
    "        return\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "    segments = np.array_split(image, 4, axis=1)\n",
    "\n",
    "    with Pool(processes=4) as pool:\n",
    "        blurred_segments = pool.map(apply_blur, segments)\n",
    "\n",
    "    blurred_image = np.hstack(blurred_segments)\n",
    "    cv2.imwrite('que-es-la-informatica-900x445.jpg', blurred_image)\n",
    "\n",
    "parallel_image_processing('que-es-la-informatica-900x445.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af7c8c",
   "metadata": {},
   "source": [
    "Explicación del código:\n",
    "\n",
    "- Importamos los módulos necesarios: cv2 para el procesamiento de imágenes y multiprocessing para el paralelismo.\n",
    "- Definimos la función apply_blur que se encargará de aplicar el filtro de desenfoque a cada segmento de la imagen.\n",
    "- La función parallel_image_processing es el punto de entrada del programa:\n",
    "- Cargamos la imagen de entrada usando cv2.imread.\n",
    "- Dividimos la imagen en 4 segmentos horizontales usando np.array_split.\n",
    "- Creamos un objeto Pool con 4 procesos y usamos pool.map para aplicar la función apply_blur a cada segmento en paralelo.\n",
    "- Unimos los segmentos procesados en paralelo usando np.hstack.\n",
    "- Guardamos la imagen resultante con el filtro de desenfoque aplicado usando cv2.imwrite.\n",
    "Finalmente, llamamos a parallel_image_processing con la ruta de la imagen de entrada.\n",
    "Este código divide la imagen en 4 segmentos horizontales, procesa cada segmento en paralelo aplicando un filtro de desenfoque, y luego une los segmentos procesados para obtener la imagen final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e51faf-02fe-45c1-a14c-ee8bf3d719f8",
   "metadata": {},
   "source": [
    "Ejercicio 2: Paralelización de operaciones matriciales con NumPy y Joblib\n",
    "\n",
    "Descripción: Paraleliza una serie de operaciones matriciales (multiplicación de matrices) utilizando Joblib.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear dos matrices grandes con numpy.\n",
    "- Dividir las matrices en sub-matrices.\n",
    "- Multiplicar las sub-matrices en paralelo utilizando Joblib.\n",
    "- Reunir los resultados y formar la matriz resultante.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa numpy.split para dividir las matrices.\n",
    "- Usa joblib.Parallel y joblib.delayed para el procesamiento paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a008cca-9d53-421d-a55f-d4a48fdc7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def multiply_sub_matrices(A, B):\n",
    "    return np.dot(A, B)\n",
    "\n",
    "def parallel_matrix_multiplication():\n",
    "    A = np.random.rand(1000, 1000)\n",
    "    B = np.random.rand(1000, 1000)\n",
    "    A_subs = np.array_split(A, 4, axis=0)\n",
    "    B_subs = np.array_split(B, 4, axis=1)\n",
    "\n",
    "    results = Parallel(n_jobs=4)(delayed(multiply_sub_matrices)(A_sub, B_sub) for A_sub in A_subs for B_sub in B_subs)\n",
    "    \n",
    "    C = np.zeros((1000, 1000))\n",
    "    for i, res in enumerate(results):\n",
    "        C[i*250:(i+1)*250, :] = res\n",
    "\n",
    "    return C\n",
    "\n",
    "C = parallel_matrix_multiplication()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6876b808",
   "metadata": {},
   "source": [
    "## MI RESPUESTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d44daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblibNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/301.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/301.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/301.8 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/301.8 kB 130.4 kB/s eta 0:00:03\n",
      "   --- ----------------------------------- 30.7/301.8 kB 130.4 kB/s eta 0:00:03\n",
      "   ----- --------------------------------- 41.0/301.8 kB 130.7 kB/s eta 0:00:02\n",
      "   --------- ----------------------------- 71.7/301.8 kB 196.3 kB/s eta 0:00:02\n",
      "   -------------- ----------------------- 112.6/301.8 kB 273.1 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 122.9/301.8 kB 276.8 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 153.6/301.8 kB 305.7 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 153.6/301.8 kB 305.7 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 174.1/301.8 kB 308.0 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 194.6/301.8 kB 327.4 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 225.3/301.8 kB 352.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 276.5/301.8 kB 378.2 kB/s eta 0:00:01\n",
      "   -------------------------------------  297.0/301.8 kB 390.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- 301.8/301.8 kB 365.8 kB/s eta 0:00:00\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.4.2\n"
     ]
    }
   ],
   "source": [
    "pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8dbc8d0-ffa3-4f05-94e8-3d72d8c7dc12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (250,250) into shape (250,1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m         C[i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m250\u001b[39m:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m250\u001b[39m, :] \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m C\n\u001b[1;32m---> 23\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_matrix_multiplication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m, in \u001b[0;36mparallel_matrix_multiplication\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mC\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m C\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (250,250) into shape (250,1000)"
     ]
    }
   ],
   "source": [
    "## Tus respuestas\n",
    "\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def multiply_sub_matrices(A, B):\n",
    "    return np.dot(A, B)\n",
    "\n",
    "def parallel_matrix_multiplication():\n",
    "    A = np.random.rand(1000, 1000)\n",
    "    B = np.random.rand(1000, 1000)\n",
    "    A_subs = np.array_split(A, 4, axis=0)\n",
    "    B_subs = np.array_split(B, 4, axis=1)\n",
    "\n",
    "    results = Parallel(n_jobs=4)(delayed(multiply_sub_matrices)(A_sub, B_sub) for A_sub in A_subs for B_sub in B_subs)\n",
    "    \n",
    "    C = np.zeros((1000, 1000))\n",
    "    for i, res in enumerate(results):\n",
    "        C[i*250:(i+1)*250, :] = res\n",
    "\n",
    "    return C\n",
    "\n",
    "C = parallel_matrix_multiplication()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23eb770",
   "metadata": {},
   "source": [
    "El error ValueError que estás obteniendo se debe a que las dimensiones de los resultados de las multiplicaciones de sub-matrices no coinciden con la forma esperada de la matriz final C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7e82b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[267.51998677 253.77049711 255.1336861  ... 263.09726463 267.01181639\n",
      "  262.88449613]\n",
      " [248.72995647 242.68951523 236.72226689 ... 242.85319727 243.96295649\n",
      "  248.97038633]\n",
      " [255.54824574 244.58366943 248.36866468 ... 252.41638165 256.50407152\n",
      "  252.7349171 ]\n",
      " ...\n",
      " [258.63498872 245.82582674 245.80638089 ... 254.72178645 260.62859669\n",
      "  256.74748074]\n",
      " [255.20844903 248.15185555 246.57276497 ... 247.03527658 254.93108123\n",
      "  253.10586547]\n",
      " [253.24177406 243.69523172 248.27539817 ... 251.60430785 255.73669502\n",
      "  256.42337291]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def multiply_sub_matrices(A, B):\n",
    "    return np.dot(A, B)\n",
    "\n",
    "def parallel_matrix_multiplication():\n",
    "    A = np.random.rand(1000, 1000)\n",
    "    B = np.random.rand(1000, 1000)\n",
    "\n",
    "    A_subs = np.array_split(A, 4, axis=0)\n",
    "    B_subs = np.array_split(B, 4, axis=1)\n",
    "\n",
    "    results = Parallel(n_jobs=4)(delayed(multiply_sub_matrices)(A_sub, B_sub) for A_sub in A_subs for B_sub in B_subs)\n",
    "\n",
    "    C = np.zeros((1000, 1000))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            C[i*250:(i+1)*250, j*250:(j+1)*250] = results[i*4 + j]\n",
    "\n",
    "    return C\n",
    "\n",
    "C = parallel_matrix_multiplication()\n",
    "print(C) # Imprime los primeros 10x10 elementos de C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b9d81-0ba4-40e2-bee0-99df775df29a",
   "metadata": {},
   "source": [
    "Ejercicio 3: Procesamiento paralelo de archivos con Dask\n",
    "\n",
    "Descripción: Utiliza Dask para procesar un conjunto de archivos CSV en paralelo, realizando una agregación (por ejemplo, promedio de una columna específica).\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Leer varios archivos CSV con Dask.\n",
    "- Procesar los archivos en paralelo para calcular el promedio de una columna específica.\n",
    "- Combinar los resultados y obtener el promedio total.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa dask.dataframe.read_csv para leer los archivos.\n",
    "- Usa dask.dataframe para realizar las operaciones en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9282f85-4257-4274-9590-ccaba542225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def parallel_csv_processing(file_paths):\n",
    "    df = dd.read_csv(file_paths)\n",
    "    average_value = df['target_column'].mean().compute()\n",
    "    return average_value\n",
    "\n",
    "file_paths = ['file1.csv', 'file2.csv', 'file3.csv', 'file4.csv']\n",
    "average = parallel_csv_processing(file_paths)\n",
    "print(f\"Average value: {average}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab89f01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask\n",
      "  Downloading dask-2024.5.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting click>=8.1 (from dask)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpickle>=1.5.0 (from dask)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting fsspec>=2021.09.0 (from dask)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alexandra\\appdata\\roaming\\python\\python312\\site-packages (from dask) (24.0)\n",
      "Collecting partd>=1.2.0 (from dask)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyyaml>=5.3.1 (from dask)\n",
      "  Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting toolz>=0.10.0 (from dask)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexandra\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1->dask) (0.4.6)\n",
      "Collecting locket (from partd>=1.2.0->dask)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Downloading dask-2024.5.1-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.2 MB 459.5 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.2 MB 438.1 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.2 MB 438.1 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.1/1.2 MB 361.0 kB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.1/1.2 MB 405.9 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.2 MB 382.3 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.2/1.2 MB 211.0 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.2 MB 211.0 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.2 MB 211.0 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.2 MB 211.0 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.2 MB 211.0 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.2 MB 211.0 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.2 MB 211.0 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.2 MB 211.0 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.2 MB 159.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.2 MB 159.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.2 MB 159.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.2 MB 159.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.2 MB 159.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.2 MB 159.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.2 MB 159.9 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.2/1.2 MB 159.9 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.2/1.2 MB 136.0 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 0.2/1.2 MB 136.0 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 0.2/1.2 MB 136.0 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 0.2/1.2 MB 136.0 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 0.2/1.2 MB 136.0 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 0.2/1.2 MB 136.0 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 0.2/1.2 MB 123.6 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 0.3/1.2 MB 139.4 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 0.3/1.2 MB 139.4 kB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 0.3/1.2 MB 149.0 kB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 0.3/1.2 MB 149.0 kB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 0.3/1.2 MB 149.0 kB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 153.4 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 153.4 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 153.4 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 153.4 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 0.4/1.2 MB 149.0 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 0.4/1.2 MB 167.0 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.4/1.2 MB 167.0 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.4/1.2 MB 167.0 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.4/1.2 MB 167.0 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.4/1.2 MB 158.1 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 0.5/1.2 MB 166.7 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 0.5/1.2 MB 166.7 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 0.5/1.2 MB 169.4 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 0.5/1.2 MB 177.4 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 0.6/1.2 MB 198.4 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 0.7/1.2 MB 235.8 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 0.8/1.2 MB 267.7 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.8/1.2 MB 273.7 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 0.9/1.2 MB 277.6 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 0.9/1.2 MB 239.3 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 0.9/1.2 MB 239.3 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.1/1.2 MB 287.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.1/1.2 MB 287.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.1/1.2 MB 287.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.1/1.2 MB 286.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 310.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 306.8 kB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 41.0/97.9 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 41.0/97.9 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 41.0/97.9 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 41.0/97.9 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 41.0/97.9 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 61.4/97.9 kB 182.2 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 61.4/97.9 kB 182.2 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 61.4/97.9 kB 182.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 81.9/97.9 kB 183.8 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 81.9/97.9 kB 183.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.2/97.9 kB 169.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 97.9/97.9 kB 170.3 kB/s eta 0:00:00\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "   ---------------------------------------- 0.0/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.1 kB ? eta -:--:--\n",
      "   ----------------- -------------------- 143.4/316.1 kB 144.4 kB/s eta 0:00:02\n",
      "   ----------------- -------------------- 143.4/316.1 kB 144.4 kB/s eta 0:00:02\n",
      "   ------------------------------ ------- 256.0/316.1 kB 234.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 307.2/316.1 kB 279.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 316.1/316.1 kB 279.6 kB/s eta 0:00:00\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.7 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 41.0/138.7 kB 991.0 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 41.0/138.7 kB 991.0 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 41.0/138.7 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 112.6/138.7 kB 598.8 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 112.6/138.7 kB 598.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 133.1/138.7 kB 491.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 138.7/138.7 kB 457.1 kB/s eta 0:00:00\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 51.2/56.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.1/56.1 kB 740.0 kB/s eta 0:00:00\n",
      "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: toolz, pyyaml, locket, fsspec, cloudpickle, click, partd, dask\n",
      "Successfully installed click-8.1.7 cloudpickle-3.0.0 dask-2024.5.1 fsspec-2024.5.0 locket-1.0.0 partd-1.4.2 pyyaml-6.0.1 toolz-0.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dask.exe is installed in 'c:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b981f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\alexandra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alexandra\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexandra\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.5 MB 330.3 kB/s eta 0:00:35\n",
      "   ---------------------------------------- 0.0/11.5 MB 330.3 kB/s eta 0:00:35\n",
      "   ---------------------------------------- 0.0/11.5 MB 330.3 kB/s eta 0:00:35\n",
      "   ---------------------------------------- 0.1/11.5 MB 403.5 kB/s eta 0:00:29\n",
      "   ---------------------------------------- 0.1/11.5 MB 403.5 kB/s eta 0:00:29\n",
      "   ---------------------------------------- 0.1/11.5 MB 379.3 kB/s eta 0:00:30\n",
      "    --------------------------------------- 0.2/11.5 MB 416.7 kB/s eta 0:00:28\n",
      "    --------------------------------------- 0.2/11.5 MB 403.5 kB/s eta 0:00:29\n",
      "    --------------------------------------- 0.2/11.5 MB 492.1 kB/s eta 0:00:23\n",
      "   - -------------------------------------- 0.3/11.5 MB 655.9 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.4/11.5 MB 732.8 kB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.5/11.5 MB 810.2 kB/s eta 0:00:14\n",
      "   - -------------------------------------- 0.6/11.5 MB 868.4 kB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.6/11.5 MB 874.1 kB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.6/11.5 MB 840.3 kB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.6/11.5 MB 828.8 kB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.7/11.5 MB 764.4 kB/s eta 0:00:15\n",
      "   -- ------------------------------------- 0.7/11.5 MB 800.8 kB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.7/11.5 MB 813.8 kB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.8/11.5 MB 813.7 kB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.8/11.5 MB 826.5 kB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.8/11.5 MB 826.5 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 0.9/11.5 MB 812.6 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 1.0/11.5 MB 843.6 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/11.5 MB 845.4 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/11.5 MB 831.6 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/11.5 MB 831.6 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/11.5 MB 831.6 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.1/11.5 MB 808.4 kB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 1.4/11.5 MB 972.6 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.7/11.5 MB 1.1 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.2/11.5 MB 1.1 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.6/11.5 MB 1.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.7/11.5 MB 1.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.9/11.5 MB 1.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.9/11.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.9/11.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 3.1/11.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.3/11.5 MB 1.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.3/11.5 MB 1.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.4/11.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.4/11.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.5/11.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.6/11.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.7/11.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.8/11.5 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 4.0/11.5 MB 1.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 4.1/11.5 MB 1.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 4.3/11.5 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.3/11.5 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.4/11.5 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.6/11.5 MB 1.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.7/11.5 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.7/11.5 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.9/11.5 MB 1.5 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 1.6 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 5.2/11.5 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.4/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.5/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.6/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.7/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.7/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.8/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.8/11.5 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.9/11.5 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.1/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.1/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.2/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.2/11.5 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.3/11.5 MB 1.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.3/11.5 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 6.3/11.5 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 6.5/11.5 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 6.6/11.5 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.7/11.5 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.9/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.1/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.3/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.4/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.5/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.5/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.6/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.8/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.9/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 8.0/11.5 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 8.0/11.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 8.1/11.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.1/11.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.1/11.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.3/11.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.5/11.5 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.7/11.5 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.7/11.5 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.8/11.5 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.8/11.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.9/11.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.1/11.5 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.4/11.5 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.7/11.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.9/11.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.6/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 81.9/505.5 kB 2.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 81.9/505.5 kB 2.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 81.9/505.5 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------- --------------------------- 143.4/505.5 kB 708.1 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 184.3/505.5 kB 740.8 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 256.0/505.5 kB 874.6 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 327.7/505.5 kB 967.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 440.3/505.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 440.3/505.5 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ---- 450.6/505.5 kB 972.0 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 471.0/505.5 kB 921.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 491.5/505.5 kB 854.8 kB/s eta 0:00:01\n",
      "   -------------------------------------  501.8/505.5 kB 827.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 505.5/505.5 kB 754.9 kB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 41.0/345.4 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 81.9/345.4 kB 2.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 81.9/345.4 kB 2.3 MB/s eta 0:00:01\n",
      "   ------------------- ------------------ 174.1/345.4 kB 952.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  337.9/345.4 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 345.4/345.4 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c32cd1-27da-40aa-8847-7ee1efa54624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\backends.py:140\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:771\u001b[0m, in \u001b[0;36mmake_reader.<locals>.read\u001b[1;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m    759\u001b[0m     urlpath,\n\u001b[0;32m    760\u001b[0m     blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    770\u001b[0m ):\n\u001b[1;32m--> 771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m        \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43massume_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massume_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_path_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_path_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:571\u001b[0m, in \u001b[0;36mread_pandas\u001b[1;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m     sample \u001b[38;5;241m=\u001b[39m blocksize\n\u001b[1;32m--> 571\u001b[0m b_out \u001b[38;5;241m=\u001b[39m \u001b[43mread_bytes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_lineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_path_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_path_column:\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\bytes\\core.py:111\u001b[0m, in \u001b[0;36mread_bytes\u001b[1;34m(urlpath, delimiter, not_zero, blocksize, sample, compression, include_path, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot do chunked reads on compressed files. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo read, set blocksize=None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m     )\n\u001b[1;32m--> 111\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fsspec\\implementations\\local.py:86\u001b[0m, in \u001b[0;36mLocalFileSystem.info\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m---> 86\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m link \u001b[38;5;241m=\u001b[39m stat\u001b[38;5;241m.\u001b[39mS_ISLNK(out\u001b[38;5;241m.\u001b[39mst_mode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file1.csv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_value\n\u001b[0;32m      9\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m average \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_csv_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m, in \u001b[0;36mparallel_csv_processing\u001b[1;34m(file_paths)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_csv_processing\u001b[39m(file_paths):\n\u001b[1;32m----> 5\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     average_value \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_column\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_value\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\backends.py:142\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod registered to the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m backend.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file1.csv'"
     ]
    }
   ],
   "source": [
    "## Tus respuestas\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def parallel_csv_processing(file_paths):\n",
    "    df = dd.read_csv(file_paths)\n",
    "    average_value = df['target_column'].mean().compute()\n",
    "    return average_value\n",
    "\n",
    "file_paths = ['file1.csv', 'file2.csv', 'file3.csv', 'file4.csv']\n",
    "average = parallel_csv_processing(file_paths)\n",
    "print(f\"Average value: {average}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19df7bc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\backends.py:140\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:771\u001b[0m, in \u001b[0;36mmake_reader.<locals>.read\u001b[1;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m    759\u001b[0m     urlpath,\n\u001b[0;32m    760\u001b[0m     blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    770\u001b[0m ):\n\u001b[1;32m--> 771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m        \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43massume_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massume_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_path_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_path_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:571\u001b[0m, in \u001b[0;36mread_pandas\u001b[1;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m     sample \u001b[38;5;241m=\u001b[39m blocksize\n\u001b[1;32m--> 571\u001b[0m b_out \u001b[38;5;241m=\u001b[39m \u001b[43mread_bytes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_lineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_path_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_path_column:\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\bytes\\core.py:111\u001b[0m, in \u001b[0;36mread_bytes\u001b[1;34m(urlpath, delimiter, not_zero, blocksize, sample, compression, include_path, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot do chunked reads on compressed files. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo read, set blocksize=None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m     )\n\u001b[1;32m--> 111\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fsspec\\implementations\\local.py:86\u001b[0m, in \u001b[0;36mLocalFileSystem.info\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m---> 86\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m link \u001b[38;5;241m=\u001b[39m stat\u001b[38;5;241m.\u001b[39mS_ISLNK(out\u001b[38;5;241m.\u001b[39mst_mode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file1.csv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_value\n\u001b[0;32m      8\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m average \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_csv_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36mparallel_csv_processing\u001b[1;34m(file_paths)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_csv_processing\u001b[39m(file_paths):\n\u001b[1;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     average_value \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_column\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_value\n",
      "File \u001b[1;32mc:\\Users\\alexandra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\backends.py:142\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod registered to the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m backend.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file1.csv'"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def parallel_csv_processing(file_paths):\n",
    "    df = dd.read_csv(file_paths)\n",
    "    average_value = df['target_column'].mean().compute()\n",
    "    return average_value\n",
    "\n",
    "file_paths = ['c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file1.csv',\n",
    "              'c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file2.csv',\n",
    "              'c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file3.csv',\n",
    "              'c:/Users/alexandra/Documents/computacion-paralela(evaluacion8)/file4.csv']\n",
    "average = parallel_csv_processing(file_paths)\n",
    "print(f\"Average value: {average}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7e484-f1b5-4a5a-bb9a-2e0cb7f85f0f",
   "metadata": {},
   "source": [
    "Ejercicio 4: Multiplicación de matrices paralela con OpenMP\n",
    "Descripción: Implementa la multiplicación de matrices utilizando OpenMP para paralelizar el cálculo.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear dos matrices grandes.\n",
    "- Paralelizar la multiplicación de matrices utilizando directivas de OpenMP.\n",
    "- Compilar y ejecutar el programa en un sistema con múltiples núcleos.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa #pragma omp parallel for para paralelizar los bucles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec33bce-8868-4b83-b080-5bc60e97fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "void parallel_matrix_multiplication(int N) {\n",
    "    int i, j, k;\n",
    "    double **A = (double **)malloc(N * sizeof(double *));\n",
    "    double **B = (double **)malloc(N * sizeof(double *));\n",
    "    double **C = (double **)malloc(N * sizeof(double *));\n",
    "    for (i = 0; i < N; i++) {\n",
    "        A[i] = (double *)malloc(N * sizeof(double));\n",
    "        B[i] = (double *)malloc(N * sizeof(double));\n",
    "        C[i] = (double *)malloc(N * sizeof(double));\n",
    "        for (j = 0; j < N; j++) {\n",
    "            A[i][j] = rand() % 100;\n",
    "            B[i][j] = rand() % 100;\n",
    "            C[i][j] = 0.0;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #pragma omp parallel for private(i, j, k) shared(A, B, C)\n",
    "    for (i = 0; i < N; i++) {\n",
    "        for (j = 0; j < N; j++) {\n",
    "            for (k = 0; k < N; k++) {\n",
    "                C[i][j] += A[i][k] * B[k][j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Imprimir una pequeña parte de la matriz resultado\n",
    "    for (i = 0; i < 5; i++) {\n",
    "        for (j = 0; j < 5; j++) {\n",
    "            printf(\"%f \", C[i][j]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    for (i = 0; i < N; i++) {\n",
    "        free(A[i]);\n",
    "        free(B[i]);\n",
    "        free(C[i]);\n",
    "    }\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int N = 1000;\n",
    "    parallel_matrix_multiplication(N);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e9b4d-cc13-4c3a-a7c1-b910aa1f1c3a",
   "metadata": {},
   "source": [
    "Ejercicio 5: Suma paralela de un vector con Pthreads\n",
    "\n",
    "Descripción: Implementa la suma de los elementos de un vector utilizando pthread para paralelizar el cálculo.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear un vector grande.\n",
    "- Dividir el vector en segmentos y asignar cada segmento a un hilo diferente.\n",
    "- Utilizar pthread para realizar la suma en paralelo y combinar los resultados.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa pthread_create y pthread_join para gestionar los hilos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee9a13-94b9-46c1-aaed-3dc2447488fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <pthread.h>\n",
    "\n",
    "#define NUM_THREADS 4\n",
    "#define VECTOR_SIZE 1000000\n",
    "\n",
    "typedef struct {\n",
    "    int start;\n",
    "    int end;\n",
    "    double *vector;\n",
    "    double sum;\n",
    "} ThreadData;\n",
    "\n",
    "void *partial_sum(void *arg) {\n",
    "    ThreadData *data = (ThreadData *)arg;\n",
    "    data->sum = 0.0;\n",
    "    for (int i = data->start; i < data->end; i++) {\n",
    "        data->sum += data->vector[i];\n",
    "    }\n",
    "    pthread_exit(NULL);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    double *vector = (double *)malloc(VECTOR_SIZE * sizeof(double));\n",
    "    for (int i = 0; i < VECTOR_SIZE; i++) {\n",
    "        vector[i] = rand() % 100;\n",
    "    }\n",
    "\n",
    "    pthread_t threads[NUM_THREADS];\n",
    "    ThreadData thread_data[NUM_THREADS];\n",
    "    int segment_size = VECTOR_SIZE / NUM_THREADS;\n",
    "\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        thread_data[i].start = i * segment_size;\n",
    "        thread_data[i].end = (i == NUM_THREADS - 1) ? VECTOR_SIZE : (i + 1) * segment_size;\n",
    "        thread_data[i].vector = vector;\n",
    "        pthread_create(&threads[i], NULL, partial_sum, (void *)&thread_data[i]);\n",
    "    }\n",
    "\n",
    "    double total_sum = 0.0;\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "        total_sum += thread_data[i].sum;\n",
    "    }\n",
    "\n",
    "    printf(\"Total sum: %f\\n\", total_sum);\n",
    "    free(vector);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389f253-7612-42a1-936c-731f14e4d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391839db-f31c-4b98-81d7-70291f518f68",
   "metadata": {},
   "source": [
    "### Paralelismo de tareas\n",
    "\n",
    "El paralelismo de tareas es una técnica de computación paralela que se enfoca en dividir un problema en múltiples tareas independientes que pueden ejecutarse simultáneamente. A diferencia del paralelismo de datos, donde la misma operación se aplica a diferentes fragmentos de datos, el paralelismo de tareas permite que distintas operaciones o funciones se ejecuten en paralelo. Esta técnica es particularmente útil en aplicaciones donde las tareas son naturalmente independientes o pueden descomponerse en sub-tareas que no dependen entre sí.\n",
    "\n",
    "\n",
    "**Conceptos fundamentales**\n",
    "\n",
    "Descomposición de tareas:\n",
    "\n",
    "- División del problema: El primer paso en el paralelismo de tareas es dividir el problema en tareas más pequeñas que pueden ejecutarse de manera independiente. Esta división debe hacerse de tal manera que minimice la dependencia y maximice la paralelización.\n",
    "- Granularidad: La granularidad se refiere al tamaño de las tareas. Las tareas gruesas son grandes y pueden ser pocas, mientras que las tareas finas son pequeñas y numerosas. Un equilibrio adecuado es esencial para maximizar la eficiencia y minimizar el overhead de gestión.\n",
    "\n",
    "**Asignación de tareas:**\n",
    "\n",
    "- Distribución dinámica vs. estática: En una asignación estática, las tareas se distribuyen a los procesadores de manera fija antes de la ejecución. En una asignación dinámica, las tareas se asignan a medida que los procesadores se desocupen, lo cual puede ayudar a equilibrar la carga.\n",
    "- Balanceo de carga: El balanceo de carga asegura que todas las unidades de procesamiento tengan una cantidad equitativa de trabajo, evitando que algunos procesadores estén inactivos mientras otros están sobrecargados.\n",
    "\n",
    "**Sincronización y comunicación:**\n",
    "\n",
    "- Sincronización de tareas: Aunque las tareas son independientes, puede ser necesario sincronizarlas en ciertos puntos para asegurar que las dependencias se manejan correctamente.\n",
    "- Comunicación entre tareas: En sistemas donde las tareas deben intercambiar datos, la comunicación debe ser eficiente para minimizar el overhead y evitar cuellos de botella.\n",
    "\n",
    "**Implementaciones y arquitecturas**\n",
    "\n",
    "Procesadores Multinúcleo:\n",
    "\n",
    "- Multiprocesadores de memoria compartida: En sistemas con múltiples núcleos en un solo chip, las tareas se pueden distribuir entre los núcleos. Estos sistemas se benefician de un acceso rápido a una memoria compartida.\n",
    "- Herramientas de programación: OpenMP es una de las herramientas más utilizadas para paralelizar tareas en sistemas de memoria compartida. Permite la paralelización de bucles y la creación de secciones paralelas de código.\n",
    "\n",
    "Clusters y grids:\n",
    "\n",
    "- Sistemas de memoria distribuida: En un cluster, cada nodo tiene su propia memoria, y las tareas se distribuyen entre los nodos. La comunicación entre nodos se realiza mediante mensajes.\n",
    "\n",
    "- Message passing interface (MPI): Es el estándar para la programación en memoria distribuida. Facilita la creación de programas que pueden ejecutar tareas en paralelo en diferentes nodos de un cluster.\n",
    "\n",
    "**Sistemas híbridos**\n",
    "\n",
    "- Combinación de memoria compartida y distribuida: Algunos sistemas combinan ambos enfoques, utilizando memoria compartida dentro de un nodo y comunicación mediante mensajes entre nodos.\n",
    "- Modelos de programación híbridos: Herramientas como MPI+OpenMP permiten aprovechar las ventajas de ambos modelos, distribuyendo tareas a nivel de nodo y paralelizándolas dentro de cada nodo.\n",
    "\n",
    "**Aplicaciones y ejemplos**\n",
    "\n",
    "Servidores web:\n",
    "\n",
    "- Manejo de solicitudes concurrentes: En un servidor web, cada solicitud de cliente puede ser manejada como una tarea independiente. Esto permite al servidor procesar múltiples solicitudes al mismo tiempo, mejorando la capacidad de respuesta.\n",
    "- Ejemplo práctico: Un servidor Apache puede utilizar hilos para manejar cada solicitud de manera concurrente, permitiendo servir páginas web a múltiples usuarios simultáneamente.\n",
    "\n",
    "Sistemas de bases de datos:\n",
    "\n",
    "- Consultas concurrentes: Las bases de datos pueden ejecutar múltiples consultas en paralelo. Cada consulta puede ser tratada como una tarea independiente, permitiendo a la base de datos manejar un gran volumen de solicitudes.\n",
    "- Ejemplo práctico: Un sistema de gestión de bases de datos como MySQL puede ejecutar varias consultas de usuarios diferentes en paralelo, mejorando la eficiencia y el rendimiento.\n",
    "\n",
    "Procesamiento de señales:\n",
    "\n",
    "- Análisis y filtrado en tiempo real: En el procesamiento de señales, diferentes etapas del análisis y filtrado pueden ser ejecutadas en paralelo. Cada etapa puede ser tratada como una tarea separada.\n",
    "- Ejemplo práctico: En un sistema de reconocimiento de voz, la pre-procesamiento de señales, la extracción de características y el reconocimiento de patrones pueden ejecutarse en paralelo para acelerar el procesamiento.\n",
    "\n",
    "**Desafíos y consideraciones**\n",
    "\n",
    "Dependencias entre tareas:\n",
    "\n",
    "- Dependencias de datos: Las dependencias entre tareas pueden complicar la paralelización. Es esencial identificar y gestionar estas dependencias para evitar bloqueos y garantizar la coherencia de los datos.\n",
    "- Técnicas de resolución: Técnicas como la descomposición en fases y el uso de barreras de sincronización pueden ayudar a manejar dependencias.\n",
    "\n",
    "Overhead de sincronización:\n",
    "\n",
    "- Costos de sincronización: La sincronización entre tareas introduce overhead. Minimizar este overhead es crucial para mantener la eficiencia.\n",
    "- Estrategias de mitigación: El uso de algoritmos de sincronización eficientes y la reducción de la frecuencia de sincronización pueden ayudar a minimizar los costos.\n",
    "\n",
    "Equilibrio de carga:\n",
    "\n",
    "- Desbalance de carga: Un desbalance en la carga de trabajo puede reducir la eficiencia del sistema. Es importante distribuir las tareas de manera que cada procesador tenga una carga similar.\n",
    "- Técnicas de balanceo: Métodos como el balanceo dinámico de carga, donde las tareas se reasignan en tiempo de ejecución, pueden ayudar a mantener el equilibrio.\n",
    "\n",
    "Comunicación y ancho de banda:\n",
    "\n",
    "- Latencia de comunicación: En sistemas de memoria distribuida, la latencia de comunicación puede ser un cuello de botella. Es esencial diseñar las tareas y el sistema de comunicación para minimizar la latencia.\n",
    "- Optimización del ancho de banda: El uso eficiente del ancho de banda de comunicación es crucial para el rendimiento. Técnicas como la agregación de mensajes y la compresión de datos pueden ayudar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b0cb9c-502f-4280-8493-6e91d81dfbfe",
   "metadata": {},
   "source": [
    "Ejercicio 6: Procesamiento paralelo de archivos con concurrent.futures\n",
    "\n",
    "Descripción: Implementa un sistema para procesar múltiples archivos de texto en paralelo, donde cada archivo se lee y se realiza una operación de conteo de palabras.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear una lista de archivos de texto.\n",
    "- Usar concurrent.futures.ThreadPoolExecutor para procesar los archivos en paralelo.\n",
    "- Contar las palabras en cada archivo y almacenar los resultados en un diccionario.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa ThreadPoolExecutor para paralelizar la lectura y el conteo de palabras.\n",
    "- Usa un diccionario compartido para almacenar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066cabb-1688-4c56-9561-15985c804ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "def count_words_in_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    word_count = len(text.split())\n",
    "    return (file_path, word_count)\n",
    "\n",
    "def parallel_word_count(file_paths):\n",
    "    results = {}\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_file = {executor.submit(count_words_in_file, file_path): file_path for file_path in file_paths}\n",
    "        for future in concurrent.futures.as_completed(future_to_file):\n",
    "            file_path = future_to_file[future]\n",
    "            try:\n",
    "                file_path, count = future.result()\n",
    "                results[file_path] = count\n",
    "            except Exception as exc:\n",
    "                print(f\"{file_path} generated an exception: {exc}\")\n",
    "    return results\n",
    "\n",
    "file_paths = [\"file1.txt\", \"file2.txt\", \"file3.txt\"]\n",
    "word_counts = parallel_word_count(file_paths)\n",
    "print(word_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341c525-5974-4a78-8f60-3120ad9ed1ac",
   "metadata": {},
   "source": [
    "Ejercicio 7: Descarga paralela de páginas Web con aiohttp y asyncio\n",
    "\n",
    "Descripción: Implementa un sistema para descargar varias páginas web en paralelo utilizando aiohttp y asyncio.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear una lista de URLs.\n",
    "- Usar aiohttp y asyncio para descargar las páginas web en paralelo.\n",
    "- Almacenar el contenido de cada página en un archivo separado.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa aiohttp para realizar solicitudes HTTP de manera asíncrona.\n",
    "- Usa asyncio para gestionar la concurrencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ddefc-b912-485f-973e-937686824e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def fetch_page(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        content = await response.text()\n",
    "        filename = url.replace(\"https://\", \"\").replace(\"/\", \"_\") + \".html\"\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(content)\n",
    "        return filename\n",
    "\n",
    "async def parallel_download(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_page(session, url) for url in urls]\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "urls = [\"https://example.com\", \"https://example.org\", \"https://example.net\"]\n",
    "results = asyncio.run(parallel_download(urls))\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ddf28-730c-4d66-a083-a6db72d020ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe04de8-e811-4a08-9513-1f78c7434d0f",
   "metadata": {},
   "source": [
    "Ejercicio 8: Evaluación de modelos en paralelo con joblib\n",
    "\n",
    "Descripción: Implementa un sistema para evaluar varios modelos de machine learning en paralelo utilizando joblib.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Entrenar varios modelos de machine learning con diferentes parámetros.\n",
    "- Usar joblib.Parallel para evaluar los modelos en paralelo.\n",
    "- Comparar los resultados y seleccionar el mejor modelo.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa joblib.Parallel y joblib.delayed para paralelizar la evaluación de los modelos.\n",
    "Usa una métrica de evaluación adecuada, como la precisión o el F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597b754-fc9d-44a1-87c6-794e43959831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def evaluate_model(n_estimators, X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return (n_estimators, accuracy_score(y_test, y_pred))\n",
    "\n",
    "def parallel_model_evaluation():\n",
    "    iris = load_iris()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "    n_estimators_list = [10, 50, 100, 200]\n",
    "    results = Parallel(n_jobs=4)(delayed(evaluate_model)(n, X_train, X_test, y_train, y_test) for n in n_estimators_list)\n",
    "    return results\n",
    "\n",
    "results = parallel_model_evaluation()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef036aca-b015-4585-93e6-c9d4f10e6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d9a96-146b-4b4b-876d-af2871c1d51f",
   "metadata": {},
   "source": [
    "Ejercicio 9: Compresión de archivos en paralelo con Pthreads\n",
    "\n",
    "Descripción: Implementa un sistema para comprimir múltiples archivos de texto en paralelo utilizando pthread.\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Crear una lista de archivos de texto.\n",
    "- Usar pthread para paralelizar la compresión de los archivos.\n",
    "- Almacenar los archivos comprimidos.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa pthread_create y pthread_join para gestionar los hilos.\n",
    "- Usa una biblioteca de compresión como zlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4fc01-5839-4a01-b6b0-fa0ca2e604f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <pthread.h>\n",
    "#include <zlib.h>\n",
    "\n",
    "typedef struct {\n",
    "    char *input_file;\n",
    "    char *output_file;\n",
    "} ThreadData;\n",
    "\n",
    "void *compress_file(void *arg) {\n",
    "    ThreadData *data = (ThreadData *)arg;\n",
    "    FILE *source = fopen(data->input_file, \"rb\");\n",
    "    FILE *dest = fopen(data->output_file, \"wb\");\n",
    "    if (!source || !dest) {\n",
    "        perror(\"File open error\");\n",
    "        pthread_exit(NULL);\n",
    "    }\n",
    "\n",
    "    char in_buffer[1024];\n",
    "    char out_buffer[1024];\n",
    "    z_stream stream = {0};\n",
    "    deflateInit(&stream, Z_DEFAULT_COMPRESSION);\n",
    "\n",
    "    int read;\n",
    "    while ((read = fread(in_buffer, 1, sizeof(in_buffer), source)) > 0) {\n",
    "        stream.avail_in = read;\n",
    "        stream.next_in = (Bytef *)in_buffer;\n",
    "        do {\n",
    "            stream.avail_out = sizeof(out_buffer);\n",
    "            stream.next_out = (Bytef *)out_buffer;\n",
    "            deflate(&stream, Z_NO_FLUSH);\n",
    "            fwrite(out_buffer, 1, sizeof(out_buffer) - stream.avail_out, dest);\n",
    "        } while (stream.avail_out == 0);\n",
    "    }\n",
    "\n",
    "    do {\n",
    "        stream.avail_out = sizeof(out_buffer);\n",
    "        stream.next_out = (Bytef *)out_buffer;\n",
    "        deflate(&stream, Z_FINISH);\n",
    "        fwrite(out_buffer, 1, sizeof(out_buffer) - stream.avail_out, dest);\n",
    "    } while (stream.avail_out == 0);\n",
    "\n",
    "    deflateEnd(&stream);\n",
    "    fclose(source);\n",
    "    fclose(dest);\n",
    "    pthread_exit(NULL);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    char *input_files[] = {\"file1.txt\", \"file2.txt\", \"file3.txt\"};\n",
    "    char *output_files[] = {\"file1.txt.gz\", \"file2.txt.gz\", \"file3.txt.gz\"};\n",
    "    int num_files = 3;\n",
    "\n",
    "    pthread_t threads[num_files];\n",
    "    ThreadData thread_data[num_files];\n",
    "\n",
    "    for (int i = 0; i < num_files; i++) {\n",
    "        thread_data[i].input_file = input_files[i];\n",
    "        thread_data[i].output_file = output_files[i];\n",
    "        pthread_create(&threads[i], NULL, compress_file, &thread_data[i]);\n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < num_files; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb75238-ebd3-41a7-bdd4-39e788b42f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35c329-9541-4f1e-bd9b-60221fd95a07",
   "metadata": {},
   "source": [
    "### Taxonomía de Flynn: SIMD y MIMD\n",
    "\n",
    "La taxonomía de Flynn es una clasificación de arquitecturas de computadoras desarrollada por Michael J. Flynn en 1966. Esta taxonomía se basa en la cantidad de flujos de instrucciones y de datos que una computadora puede manejar simultáneamente, dividiéndose en cuatro categorías principales: SISD (Single Instruction, Single Data), SIMD (Single Instruction, Multiple Data), MISD (Multiple Instruction, Single Data) y MIMD (Multiple Instruction, Multiple Data). Entre estas, SIMD y MIMD son las más relevantes y ampliamente utilizadas en sistemas paralelos y distribuidos.\n",
    "\n",
    "**SIMD (Single Instruction, Multiple Data)**\n",
    "SIMD, o Single Instruction, Multiple Data, es una arquitectura que permite a una única instrucción operar sobre múltiples elementos de datos simultáneamente. Este enfoque es particularmente útil en aplicaciones que involucran grandes volúmenes de datos y operaciones repetitivas, como procesamiento de imágenes, gráficos por computadora, simulaciones científicas, y machine learning.\n",
    "\n",
    "En una arquitectura SIMD, una única unidad de control emite una instrucción que se aplica simultáneamente a múltiples unidades de procesamiento. Cada unidad de procesamiento realiza la misma operación en diferentes conjuntos de datos de manera sincronizada. Por ejemplo, en un procesador SIMD, una instrucción de suma podría sumar simultáneamente pares de números almacenados en diferentes registros o posiciones de memoria.\n",
    "\n",
    "**Ventajas**\n",
    "\n",
    "- Eficiencia en el procesamiento de datos: SIMD es extremadamente eficiente para operaciones vectoriales y matriciales, donde la misma operación se aplica a grandes conjuntos de datos.\n",
    "- Mejor utilización del hardware: Aprovecha mejor los recursos del hardware al permitir que múltiples datos sean procesados en paralelo.\n",
    "Aceleración del Rendimiento: Puede mejorar significativamente el rendimiento de aplicaciones que son inherentemente paralelas, reduciendo el tiempo de ejecución total.\n",
    "\n",
    "**Desventajas**\n",
    "\n",
    "- Flexibilidad limitada: SIMD es menos flexible para aplicaciones que no pueden ser fácilmente paralelizadas a nivel de datos.\n",
    "- Sobrecarga de Control: El manejo de múltiples datos con una sola instrucción puede requerir una mayor complejidad en la gestión de control y sincronización.\n",
    "- Limitaciones en Diversidad de Tareas: No es adecuado para tareas que requieren diferentes operaciones simultáneamente.\n",
    "\n",
    "**Ejemplos de implementaciones**\n",
    "\n",
    "- Vectores y matrices en procesadores de gráficos (GPUs): Los GPUs son el ejemplo más común de arquitecturas SIMD, donde miles de núcleos ejecutan las mismas operaciones en diferentes píxeles de una imagen.\n",
    "- Extensiones SIMD en CPUs: Extensiones como SSE (Streaming SIMD Extensions) y AVX (Advanced Vector Extensions) en procesadores x86 permiten operaciones SIMD en CPUs.\n",
    "\n",
    "**MIMD (Multiple Instruction, Multiple Data)**\n",
    "\n",
    "MIMD, o Multiple Instruction, Multiple Data, es una arquitectura que permite a múltiples unidades de procesamiento ejecutar diferentes instrucciones sobre diferentes conjuntos de datos simultáneamente. Este enfoque es más flexible y adecuado para una amplia gama de aplicaciones, incluyendo sistemas multiprocesador, supercomputadoras y clusters de computadoras.\n",
    "\n",
    "En una arquitectura MIMD, cada procesador tiene su propia unidad de control y puede ejecutar instrucciones independientemente de los otros procesadores. Esto permite que diferentes procesadores ejecuten distintos programas o partes de un programa en diferentes datos al mismo tiempo. Los procesadores en un sistema MIMD pueden trabajar en tareas completamente independientes o colaborar en una tarea distribuida.\n",
    "\n",
    "**Ventajas**\n",
    "\n",
    "- Flexibilidad y versatilidad: MIMD es extremadamente flexible y puede manejar una amplia variedad de tareas y aplicaciones, desde simulaciones científicas hasta servidores web.\n",
    "- Escalabilidad: Permite una fácil escalabilidad agregando más procesadores para aumentar la capacidad de procesamiento.\n",
    "- Eficiencia en multiprogramación: Puede ejecutar múltiples programas o hilos de un programa simultáneamente, aprovechando al máximo los recursos del sistema.\n",
    "\n",
    "**Desventajas**\n",
    "\n",
    "- Complejidad en sincronización: La coordinación y sincronización entre múltiples procesadores pueden ser complejas y costosas en términos de tiempo y recursos.\n",
    "- Consumo de energía: Los sistemas MIMD pueden consumir más energía debido al uso de múltiples unidades de control y procesamiento.\n",
    "- Desafíos en diseño y programación: La programación para sistemas MIMD puede ser más complicada, requiriendo técnicas avanzadas de paralelismo y gestión de recursos.\n",
    "\n",
    "**Ejemplos de implementaciones**\n",
    "\n",
    "- Multiprocesadores simétricos (SMP): Sistemas donde múltiples procesadores comparten la misma memoria y pueden trabajar de manera cooperativa en diferentes partes de una aplicación.\n",
    "- Clusters de computadoras: Conjuntos de computadoras conectadas que trabajan juntas en una tarea común, utilizando paradigmas de programación distribuidos como MPI (Message Passing Interface).\n",
    "- Supercomputadoras: Utilizan miles de procesadores MIMD para realizar cálculos intensivos y simulaciones científicas complejas.\n",
    "\n",
    "#### Comparación entre SIMD y MIMD\n",
    "\n",
    "**Aplicabilidad**\n",
    "- SIMD: Ideal para aplicaciones con alta coherencia de datos y operaciones repetitivas como procesamiento multimedia, gráficos, y análisis de datos.\n",
    "- MIMD: Adecuado para aplicaciones más complejas y diversas, como servidores web, bases de datos, y simulaciones científicas.\n",
    "\n",
    "Eficiencia y flexibilidad\n",
    "- SIMD: Ofrece alta eficiencia en tareas específicas, pero es menos flexible para aplicaciones variadas.\n",
    "- MIMD: Proporciona gran flexibilidad y capacidad de manejar tareas diversas, aunque puede ser menos eficiente en algunas aplicaciones específicas debido a la sobrecarga de control.\n",
    "\n",
    "Diseño y programación\n",
    "- SIMD: Menos complejo en términos de diseño y programación para aplicaciones adecuadas, pero con limitaciones en la adaptabilidad a diferentes tipos de tareas.\n",
    "- MIMD: Más complejo en diseño y programación, pero ofrece un entorno más robusto para una amplia gama de aplicaciones y técnicas de paralelismo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985a55c-c48e-45a7-9793-a36886eb6468",
   "metadata": {},
   "source": [
    "### Ejemplos teóricos\n",
    "\n",
    "**SIMD (Single Instruction, Multiple Data)**:\n",
    "\n",
    "Teórico:\n",
    "\n",
    "- Procesamiento de imágenes: Imagina que tienes una imagen en escala de grises representada como una matriz de píxeles y quieres aumentar el brillo de cada píxel en un 10%. En una arquitectura SIMD, una única instrucción de suma puede aplicarse simultáneamente a todos los píxeles de la imagen. Esto significa que, en lugar de procesar cada píxel individualmente, el sistema procesa múltiples píxeles al mismo tiempo.\n",
    "\n",
    "- Simulación de dinámica de fluidos: En simulaciones de dinámica de fluidos, se puede dividir el espacio de simulación en celdas y aplicar las mismas ecuaciones a cada celda para calcular las interacciones de fluidos. En una arquitectura SIMD, una única instrucción puede actualizar simultáneamente el estado de múltiples celdas, acelerando considerablemente la simulación.\n",
    "- Multiplicación de matrices: En cálculos científicos, la multiplicación de matrices es una operación común. En SIMD, cada elemento de la matriz resultante puede calcularse simultáneamente aplicando la misma instrucción a diferentes elementos de las matrices de entrada, acelerando significativamente el cálculo.\n",
    "- Procesamiento de señales: Imagina que tienes una señal de audio representada como un array de muestras y quieres aplicar un filtro paso bajo a esta señal. En una arquitectura SIMD, una única instrucción de multiplicación puede aplicarse simultáneamente a múltiples muestras de la señal, filtrando varias partes de la señal al mismo tiempo.\n",
    "\n",
    "**MIMD (Multiple Instruction, Multiple Data)**:\n",
    "\n",
    "Teórico:\n",
    "\n",
    "- Servidores web: Imagina un servidor web que maneja múltiples solicitudes de clientes simultáneamente. Cada solicitud puede requerir diferentes operaciones, como recuperar datos de una base de datos, procesar los datos y generar una página web. En una arquitectura MIMD, diferentes procesadores pueden manejar diferentes solicitudes de clientes de manera concurrente, cada uno ejecutando diferentes instrucciones en diferentes datos.\n",
    "\n",
    "- Simulaciones científicas Complejas: En simulaciones científicas que requieren cálculos complejos y variados, como la predicción del clima, diferentes procesadores pueden trabajar en diferentes partes de la simulación. Por ejemplo, un procesador podría calcular la temperatura en una región específica, mientras que otro calcula la presión atmosférica en una región diferente, y ambos cálculos se ejecutan en paralelo.\n",
    "- Bases de datos distribuidas: En una base de datos distribuida, diferentes nodos pueden ejecutar diferentes consultas SQL en paralelo. Mientras un nodo puede estar ejecutando una consulta de selección, otro nodo puede estar ejecutando una consulta de inserción, y ambos operan sobre diferentes subconjuntos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f3dc8-986d-4994-936c-c6adb1cec52f",
   "metadata": {},
   "source": [
    "### Ejemplos prácticos\n",
    "\n",
    "SIMD (Single Instruction, Multiple Data):\n",
    "\n",
    "\n",
    "Procesamiento de Imágenes con OpenCV y NumPy (Python): En este ejemplo, usaremos NumPy y OpenCV para aplicar un filtro de desenfoque a una imagen utilizando operaciones vectorizadas que son una forma de SIMD en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c0802-3279-4ecf-91c3-744994d7d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def apply_blur(image):\n",
    "    return cv2.GaussianBlur(image, (15, 15), 0)\n",
    "\n",
    "image = cv2.imread('input_image.jpg')\n",
    "blurred_image = apply_blur(image)\n",
    "cv2.imwrite('blurred_image.jpg', blurred_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c766fd-4ed6-4964-8965-d8e1dc729229",
   "metadata": {},
   "source": [
    "Extensiones SIMD en C con SSE: Usando instrucciones SSE en C para sumar elementos de dos vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27f877-deb4-46c0-91d6-b3458a65fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <xmmintrin.h>\n",
    "\n",
    "void add_float_arrays(float *a, float *b, float *result, int n) {\n",
    "    for (int i = 0; i < n; i += 4) {\n",
    "        __m128 va = _mm_load_ps(&a[i]);\n",
    "        __m128 vb = _mm_load_ps(&b[i]);\n",
    "        __m128 vr = _mm_add_ps(va, vb);\n",
    "        _mm_store_ps(&result[i], vr);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float a[4] = {1.0, 2.0, 3.0, 4.0};\n",
    "    float b[4] = {5.0, 6.0, 7.0, 8.0};\n",
    "    float result[4];\n",
    "    add_float_arrays(a, b, result, 4);\n",
    "    for (int i = 0; i < 4; i++) {\n",
    "        printf(\"%f\\n\", result[i]);\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7e37c-f57e-4fe3-a4bc-1f14942c53cc",
   "metadata": {},
   "source": [
    "Operaciones vectoriales en Numpy (Python): Usar Numpy para realizar operaciones vectoriales en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897cf2c1-f96c-4722-8c62-261bb14fd369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vector_addition(a, b):\n",
    "    return np.add(a, b)\n",
    "\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "result = vector_addition(a, b)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937f8fc-67f4-47fa-b03d-c0e52324930b",
   "metadata": {},
   "source": [
    "Procesamiento SIMD con AVX en C: Usar instrucciones AVX para realizar la suma de elementos de dos vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc6725-d03b-46bf-850e-de1f0b5bab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <immintrin.h>\n",
    "\n",
    "void add_float_arrays_avx(float *a, float *b, float *result, int n) {\n",
    "    for (int i = 0; i < n; i += 8) {\n",
    "        __m256 va = _mm256_load_ps(&a[i]);\n",
    "        __m256 vb = _mm256_load_ps(&b[i]);\n",
    "        __m256 vr = _mm256_add_ps(va, vb);\n",
    "        _mm256_store_ps(&result[i], vr);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float a[8] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0};\n",
    "    float b[8] = {9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};\n",
    "    float result[8];\n",
    "    add_float_arrays_avx(a, b, result, 8);\n",
    "    for (int i = 0; i < 8; i++) {\n",
    "        printf(\"%f\\n\", result[i]);\n",
    "    }\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470db6ce-12c6-413a-8eab-7738fdb874a1",
   "metadata": {},
   "source": [
    "MIMD (Multiple Instruction, Multiple Data):\n",
    "\n",
    "Servidor Web Concurrente en Python con asyncio: Implementación de un servidor web simple que maneja múltiples solicitudes de clientes en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c9b8a-1378-4bb7-a940-37baeea7095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def handle_request(reader, writer):\n",
    "    data = await reader.read(100)\n",
    "    message = data.decode()\n",
    "    print(f\"Received {message}\")\n",
    "    writer.write(data)\n",
    "    await writer.drain()\n",
    "    writer.close()\n",
    "\n",
    "async def main():\n",
    "    server = await asyncio.start_server(handle_request, '127.0.0.1', 8888)\n",
    "    async with server:\n",
    "        await server.serve_forever()\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189bcc79-4a95-469f-abc3-cbcef60f4acf",
   "metadata": {},
   "source": [
    "Multiprocesamiento en C con Pthreads: Implementación de la suma paralela de elementos en un array usando pthread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2afd7e-4527-4599-b5cf-eb5c880829bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <pthread.h>\n",
    "\n",
    "#define NUM_THREADS 4\n",
    "#define ARRAY_SIZE 1000\n",
    "\n",
    "typedef struct {\n",
    "    int *array;\n",
    "    int start;\n",
    "    int end;\n",
    "    int sum;\n",
    "} ThreadData;\n",
    "\n",
    "void *partial_sum(void *arg) {\n",
    "    ThreadData *data = (ThreadData *)arg;\n",
    "    data->sum = 0;\n",
    "    for (int i = data->start; i < data->end; i++) {\n",
    "        data->sum += data->array[i];\n",
    "    }\n",
    "    pthread_exit(NULL);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int array[ARRAY_SIZE];\n",
    "    for (int i = 0; i < ARRAY_SIZE; i++) {\n",
    "        array[i] = rand() % 10;\n",
    "    }\n",
    "\n",
    "    pthread_t threads[NUM_THREADS];\n",
    "    ThreadData thread_data[NUM_THREADS];\n",
    "    int segment_size = ARRAY_SIZE / NUM_THREADS;\n",
    "\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        thread_data[i].array = array;\n",
    "        thread_data[i].start = i * segment_size;\n",
    "        thread_data[i].end = (i + 1) * segment_size;\n",
    "        pthread_create(&threads[i], NULL, partial_sum, &thread_data[i]);\n",
    "    }\n",
    "\n",
    "    int total_sum = 0;\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "        total_sum += thread_data[i].sum;\n",
    "    }\n",
    "\n",
    "    printf(\"Total sum: %d\\n\", total_sum);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc7ef9-3400-4b50-8276-0cacf19fee53",
   "metadata": {},
   "source": [
    "Ejecutar diferentes tareas concurrentes en Python con concurrent.futures: Ejecutar tareas que calculan el cuadrado y el cubo de diferentes números en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa9907-5fbf-4ebf-acf9-174f3833595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def calculate_square(n):\n",
    "    return n * n\n",
    "\n",
    "def calculate_cube(n):\n",
    "    return n * n * n\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(calculate_square, i) for i in range(5)] + \\\n",
    "              [executor.submit(calculate_cube, i) for i in range(5, 10)]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        print(future.result())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6dbfc-976b-4ca2-9d41-a5424dd37e35",
   "metadata": {},
   "source": [
    "Simulación de Monte Carlo en C con Pthreads: Usar pthread para realizar simulaciones de Monte Carlo en paralelo para estimar el valor de Pi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e782fb6-7b88-443e-8e5a-2bd38cb785d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <pthread.h>\n",
    "#include <math.h>\n",
    "\n",
    "#define NUM_THREADS 4\n",
    "#define NUM_POINTS 1000000\n",
    "\n",
    "typedef struct {\n",
    "    int points_inside_circle;\n",
    "    int num_points;\n",
    "} ThreadData;\n",
    "\n",
    "void *monte_carlo_pi(void *arg) {\n",
    "    ThreadData *data = (ThreadData *)arg;\n",
    "    int points_inside_circle = 0;\n",
    "    unsigned int seed = rand();\n",
    "    for (int i = 0; i < data->num_points; i++) {\n",
    "        double x = (double)rand_r(&seed) / RAND_MAX;\n",
    "        double y = (double)rand_r(&seed) / RAND_MAX;\n",
    "        if (x * x + y * y <= 1.0) {\n",
    "            points_inside_circle++;\n",
    "        }\n",
    "    }\n",
    "    data->points_inside_circle = points_inside_circle;\n",
    "    pthread_exit(NULL);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    pthread_t threads[NUM_THREADS];\n",
    "    ThreadData thread_data[NUM_THREADS];\n",
    "    int points_per_thread = NUM_POINTS / NUM_THREADS;\n",
    "\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        thread_data[i].num_points = points_per_thread;\n",
    "        pthread_create(&threads[i], NULL, monte_carlo_pi, &thread_data[i]);\n",
    "    }\n",
    "\n",
    "    int total_points_inside_circle = 0;\n",
    "    for (int i = 0; i < NUM_THREADS; i++) {\n",
    "        pthread_join(threads[i], NULL);\n",
    "        total_points_inside_circle += thread_data[i].points_inside_circle;\n",
    "    }\n",
    "\n",
    "    double pi_estimate = (4.0 * total_points_inside_circle) / NUM_POINTS;\n",
    "    printf(\"Estimated value of Pi: %f\\n\", pi_estimate);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae065998-9c61-4f23-a9ae-51c8cacc1cda",
   "metadata": {},
   "source": [
    "### Paralelismo a nivel de instrucción (ILP - Instruction-Level Parallelism)\n",
    "\n",
    "El paralelismo a nivel de instrucción (ILP, por sus siglas en inglés) es una técnica de arquitectura de computadoras que busca mejorar el rendimiento de los procesadores al ejecutar múltiples instrucciones en paralelo dentro de un solo núcleo de procesamiento. A diferencia del paralelismo de tareas o datos, que distribuye las cargas de trabajo entre múltiples núcleos o procesadores, ILP se centra en la ejecución simultánea de múltiples instrucciones individuales desde un flujo de instrucciones secuencial.\n",
    "\n",
    "**Conceptos fundamentales**\n",
    "\n",
    "- Pipeline de instrucciones: El pipeline de instrucciones es una técnica básica que permite la superposición de diferentes etapas de procesamiento de instrucciones, tales como la búsqueda, decodificación, ejecución, y escritura de resultados. Cada etapa del pipeline puede operar en una instrucción diferente al mismo tiempo, lo que permite que múltiples instrucciones sean procesadas simultáneamente en distintas fases del pipeline.\n",
    "\n",
    "- Superescalaridad: Un procesador superescalar puede emitir y ejecutar más de una instrucción por ciclo de reloj. Esto se logra mediante la duplicación de ciertas unidades funcionales dentro del procesador, como las unidades de punto flotante o las unidades de enteros, permitiendo que múltiples instrucciones sean ejecutadas en paralelo.\n",
    "\n",
    "- Reordenamiento de instrucciones: Para maximizar la utilización del pipeline, los procesadores modernos implementan técnicas de reordenamiento de instrucciones. Esto permite que las instrucciones que no tienen dependencias de datos puedan ser ejecutadas antes que otras que sí las tienen, reduciendo así los ciclos de espera y aumentando el paralelismo.\n",
    "\n",
    "Predicción de bifurcaciones: Las bifurcaciones en el flujo de control de un programa pueden causar retrasos en el pipeline, ya que el procesador debe decidir cuál camino de ejecución seguir. La predicción de bifurcaciones intenta anticipar la dirección que tomará una bifurcación y carga las instrucciones correspondientes en el pipeline. Si la predicción es correcta, el procesamiento continúa sin interrupciones; si es incorrecta, las instrucciones incorrectas deben ser descartadas, lo que introduce un retraso.\n",
    "\n",
    "Ejecución especulativa: La ejecución especulativa es una técnica que trabaja en conjunto con la predicción de bifurcaciones. El procesador ejecuta instrucciones basadas en predicciones antes de confirmar que son necesarias. Si la predicción es correcta, se ha ganado tiempo al haber adelantado trabajo; si no, los resultados se descartan y el procesador reanudará la ejecución desde el punto correcto.\n",
    "\n",
    "**Ejemplos y técnicas de implementación**\n",
    "\n",
    "- Pipeline clásico:\n",
    "    * Etapas del pipeline: En un pipeline típico, hay varias etapas que una instrucción debe atravesar. Un ejemplo básico incluye las etapas de fetch (búsqueda), decode (decodificación), execute (ejecución), memory access (acceso a memoria) y write-back (escritura de resultados).\n",
    "    *  Mejora del rendimiento: Al tener múltiples instrucciones en diferentes etapas del pipeline simultáneamente, se incrementa el rendimiento al aprovechar al máximo cada ciclo de reloj.\n",
    "- Procesadores superescalares:\n",
    "   * Duplicación de unidades funcionales: Un procesador superescalar puede tener múltiples unidades aritmético-lógicas (ALU), lo que le permite ejecutar múltiples operaciones aritméticas en paralelo.\n",
    "   * Decodificadores múltiples: Varios decodificadores de instrucciones permiten que múltiples instrucciones sean decodificadas y emitidas al mismo tiempo.\n",
    "  \n",
    "- Out-of-Order execution:\n",
    "   * Desplazamiento de dependencias: Las instrucciones que no dependen de los resultados de otras instrucciones pueden ser ejecutadas antes de tiempo, adelantando el trabajo en lugar de esperar a que las instrucciones previas se completen.\n",
    "   * Reensamblado de resultados: Al final, los resultados de las instrucciones se reensamblan en el orden correcto, asegurando que el flujo de programa se mantenga coherente.\n",
    "\n",
    "- Predicción de Bifurcaciones:\n",
    "   * Historial de bifurcaciones: Los procesadores utilizan tablas de historial de bifurcaciones que registran los patrones de bifurcaciones anteriores para hacer predicciones más precisas.\n",
    "   * Algoritmos de predicción: Algoritmos como la predicción bimodal y la predicción con historial global se utilizan para mejorar la exactitud de las predicciones.\n",
    "\n",
    "- Ejecución especulativa:\n",
    "   * Ejecución basada en predicciones: Las instrucciones se ejecutan especulativamente basadas en la predicción de bifurcaciones. Si la predicción es incorrecta, el procesador deshace las instrucciones ejecutadas incorrectamente.\n",
    "   * Manejo de errores: Mecanismos de control garantizan que cualquier efecto secundario de las ejecuciones especulativas incorrectas sea revertido, manteniendo la integridad del estado del procesador.\n",
    "\n",
    "**Beneficios del ILP**\n",
    "\n",
    "- ILP permite a los procesadores ejecutar múltiples instrucciones en paralelo, lo que resulta en un mejor rendimiento y una mayor eficiencia en el uso del hardware disponible.\n",
    "- Al reordenar las instrucciones y predecir bifurcaciones, se minimizan los ciclos de espera y se maximiza la utilización del pipeline, reduciendo los tiempos muertos y mejorando la velocidad de procesamiento.\n",
    "- La capacidad de ejecutar instrucciones fuera de orden y especulativamente proporciona flexibilidad, permitiendo que el procesador maneje dependencias de datos y bifurcaciones de manera más eficiente.\n",
    "\n",
    "**Desafíos del ILP**\n",
    "- La implementación de ILP requiere hardware complejo, incluyendo múltiples unidades funcionales, decodificadores y mecanismos de control de dependencias, lo que incrementa los costos y la dificultad de diseño.\n",
    "- La cantidad de paralelismo disponible a nivel de instrucción está limitada por la naturaleza del código y las dependencias de datos, lo que puede restringir la cantidad de ILP que se puede explotar.\n",
    "- El hardware adicional y las operaciones especulativas pueden incrementar significativamente el consumo de energía, lo cual es un factor crítico en el diseño de procesadores, especialmente en dispositivos móviles y sistemas embebidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb3c55-c708-4bdc-aaab-dc3a825932ed",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1 . Explica cómo funciona el pipeline en una CPU moderna. Describa las diferentes etapas del pipeline y cómo se superponen para mejorar el rendimiento del procesador.\n",
    "\n",
    " Respuesta esperada:\n",
    " \n",
    " Debes explicar:\n",
    "\n",
    "- Las etapas típicas del pipeline (Fetch, Decode, Execute, Memory Access, Write-back).\n",
    "- Cómo cada etapa del pipeline puede trabajar en una instrucción diferente simultáneamente.\n",
    "-  Cómo el pipelining mejora el rendimiento al permitir que múltiples instrucciones estén en diferentes fases de ejecución al mismo tiempo.\n",
    "\n",
    "2 . Describe el concepto de reordenamiento de instrucciones (out-of-order execution) y cómo ayuda a mejorar el rendimiento en procesadores modernos. Incluya un ejemplo ilustrativo.\n",
    "\n",
    " Respuesta esperada:\n",
    " \n",
    " Debes explicar:\n",
    "    \n",
    "- Cómo el procesador puede reordenar las instrucciones para ejecutar otras que no tengan dependencias mientras espera por las que sí tienen.\n",
    "- Ejemplo: Si una instrucción A está esperando un dato que se está calculando en otra instrucción B, el procesador puede ejecutar una instrucción C que no depende de B mientras espera.\n",
    "\n",
    "3 . Discute cómo la predicción de bifurcaciones (branch prediction) se utiliza para mejorar el flujo de instrucciones en el pipeline. Explica los conceptos de predicción estática y dinámica.\n",
    "\n",
    " Respuesta esperada:\n",
    " \n",
    " Debes explicar:\n",
    "    \n",
    "- Predicción estática: decisiones fijas basadas en reglas predefinidas (e.g., siempre predecir que la bifurcación no se tomará).\n",
    "- Predicción dinámica: decisiones basadas en el historial de ejecución de las bifurcaciones (e.g., tablas de historial de bifurcaciones).\n",
    "- Cómo estas técnicas reducen los ciclos de burbuja en el pipeline al anticipar la dirección de las bifurcaciones.\n",
    "\n",
    "4 . Implementa un programa en C que simule el pipeline de un procesador simple con las etapas de Fetch, Decode, Execute, Memory Access, y Write-back. Simule la ejecución de un conjunto de instrucciones y muestre cómo las instrucciones se superponen en el pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2038929-d250-417e-be04-de00eb032810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "\n",
    "#define NUM_INSTRUCTIONS 5\n",
    "\n",
    "const char *instructions[NUM_INSTRUCTIONS] = {\n",
    "    \"LOAD R1, 100\",\n",
    "    \"ADD R2, R1, R3\",\n",
    "    \"STORE R2, 200\",\n",
    "    \"SUB R4, R2, R5\",\n",
    "    \"LOAD R3, 300\"\n",
    "};\n",
    "\n",
    "void fetch(int cycle) {\n",
    "    printf(\"Cycle %d: Fetching instruction\\n\", cycle);\n",
    "}\n",
    "\n",
    "void decode(int cycle) {\n",
    "    printf(\"Cycle %d: Decoding instruction\\n\", cycle);\n",
    "}\n",
    "\n",
    "void execute(int cycle) {\n",
    "    printf(\"Cycle %d: Executing instruction\\n\", cycle);\n",
    "}\n",
    "\n",
    "void memory_access(int cycle) {\n",
    "    printf(\"Cycle %d: Accessing memory\\n\", cycle);\n",
    "}\n",
    "\n",
    "void write_back(int cycle) {\n",
    "    printf(\"Cycle %d: Writing back to register\\n\", cycle);\n",
    "}\n",
    "\n",
    "void simulate_pipeline() {\n",
    "    for (int i = 0; i < NUM_INSTRUCTIONS + 4; i++) {\n",
    "        if (i < NUM_INSTRUCTIONS) {\n",
    "            printf(\"Instruction: %s\\n\", instructions[i]);\n",
    "        }\n",
    "        if (i >= 4) {\n",
    "            write_back(i);\n",
    "        }\n",
    "        if (i >= 3) {\n",
    "            memory_access(i);\n",
    "        }\n",
    "        if (i >= 2) {\n",
    "            execute(i);\n",
    "        }\n",
    "        if (i >= 1) {\n",
    "            decode(i);\n",
    "        }\n",
    "        if (i < NUM_INSTRUCTIONS) {\n",
    "            fetch(i);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    simulate_pipeline();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ececc-e6c3-412a-a993-bfc42deab607",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67e7b7-0311-429a-83af-4379ef3e17e2",
   "metadata": {},
   "source": [
    "5 . Implementa un programa en C que demuestre el reordenamiento de instrucciones. Crea un conjunto de instrucciones donde algunas dependan de los resultados de otras y optimice el orden de ejecución para mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407043b-c81d-47f6-9c8b-de06181ec498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "\n",
    "void instruction_A() {\n",
    "    printf(\"Instruction A: Load data into R1\\n\");\n",
    "}\n",
    "\n",
    "void instruction_B() {\n",
    "    printf(\"Instruction B: Perform computation using R1\\n\");\n",
    "}\n",
    "\n",
    "void instruction_C() {\n",
    "    printf(\"Instruction C: Independent computation\\n\");\n",
    "}\n",
    "\n",
    "void instruction_D() {\n",
    "    printf(\"Instruction D: Use result from B\\n\");\n",
    "}\n",
    "\n",
    "void execute_instructions_in_order() {\n",
    "    instruction_A();\n",
    "    instruction_B();\n",
    "    instruction_C();\n",
    "    instruction_D();\n",
    "}\n",
    "\n",
    "void execute_instructions_out_of_order() {\n",
    "    instruction_A();\n",
    "    instruction_C(); // Moved up to avoid waiting for instruction B\n",
    "    instruction_B();\n",
    "    instruction_D();\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"Executing instructions in order:\\n\");\n",
    "    execute_instructions_in_order();\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    printf(\"Executing instructions out of order:\\n\");\n",
    "    execute_instructions_out_of_order();\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344243a-d5b2-40e1-9229-76c507e7ea7d",
   "metadata": {},
   "source": [
    "6 . Implementa un programa en Python que simule un predictor de bifurcaciones simple. Use un historial para predecir si una bifurcación será tomada o no y ajuste las predicciones basadas en los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71302f-97ff-4ec5-8b20-dfa37ec28eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchPredictor:\n",
    "    def __init__(self):\n",
    "        self.history = {}\n",
    "\n",
    "    def predict(self, branch):\n",
    "        return self.history.get(branch, False)\n",
    "\n",
    "    def update(self, branch, taken):\n",
    "        self.history[branch] = taken\n",
    "\n",
    "def main():\n",
    "    predictor = BranchPredictor()\n",
    "    branches = [(\"branch1\", True), (\"branch2\", False), (\"branch1\", False), (\"branch2\", True)]\n",
    "\n",
    "    for branch, taken in branches:\n",
    "        prediction = predictor.predict(branch)\n",
    "        print(f\"Predicted: {prediction}, Actual: {taken}\")\n",
    "        predictor.update(branch, taken)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc97642-ba07-4c03-8170-d26c61787801",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14926d5-be36-4895-b579-f37e7799fa24",
   "metadata": {},
   "source": [
    "7 . Implementa un programa en Python que demuestre el paralelismo de instrucciones utilizando hilos. Crea un conjunto de tareas independientes que se ejecuten en paralelo utilizando el módulo threading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd752b-c3b9-42ce-aeef-f614907ed82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def task_1():\n",
    "    print(\"Task 1: Executing\")\n",
    "\n",
    "def task_2():\n",
    "    print(\"Task 2: Executing\")\n",
    "\n",
    "def task_3():\n",
    "    print(\"Task 3: Executing\")\n",
    "\n",
    "def task_4():\n",
    "    print(\"Task 4: Executing\")\n",
    "\n",
    "def main():\n",
    "    threads = []\n",
    "    tasks = [task_1, task_2, task_3, task_4]\n",
    "    for task in tasks:\n",
    "        thread = threading.Thread(target=task)\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3abe98-a076-407c-b43b-1a0483ff9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
